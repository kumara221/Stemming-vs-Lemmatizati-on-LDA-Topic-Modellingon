[    
      {
        "abstract": "Technical progress in the open-source self replicating rapid prototyper (RepRap) community has enabled a distributed form of additive manufacturing to expand rapidly using polymer-based materials. However, the lack of an open-source metal alternative and the high capital costs and slow throughput of proprietary commercialized metal 3-D printers has severely restricted their deployment. The applications of commercialized metal 3-D printers are limited to only rapid prototyping and expensive finished products. This severely restricts the access of the technology for small and medium enterprises, the developing world and for use in laboratories. This paper reports on the development of a<$2000open-source metal 3-D printer. The metal 3-D printer is controlled with an open-source micro-controller and is a combination of a low-cost commercial gas-metal arc welder and a derivative of the Rostock, a deltabot RepRap. The bill of materials, electrical and mechanical design schematics, and basic construction and operating procedures are provided. A preliminary technical analysis of the properties of the 3-D printer and the resultant steel products are performed. The results of printing customized functional metal parts are discussed and conclusions are drawn about the potential for the technology and the future work necessary for the mass distribution of this technology."
    },
    {
        "abstract": "Abstractive dialogue summarization is a challenging task for several reasons. First, most of the key information in a conversation is scattered across utterances through multi-party interactions with different textual styles. Second, dialogues are often informal structures, wherein different individuals express personal perspectives, unlike text summarization, tasks that usually target formal documents such as news articles. To address these issues, we focused on the association between utterances from individual speakers and unique syntactic structures. Speakers have unique textual styles that can contain linguistic information, such as voiceprint. To do this, we used ad-hoc analysis to explore speakers’ text styles and constructed a syntax-aware model by leveraging linguistic information (i.e., POS tagging), which alleviates the above issues by inherently distinguishing utterances from individual speakers. Our approach allows for both data and model-centric investigation. Also, we employed multi-task learning of both syntax-aware information and dialogue summarization. To the best of our knowledge, our approach is the first method to apply multi-task learning to the dialogue summarization task. Experiments on a SAMSum corpus (a large-scale dialogue summarization corpus) demonstrated that our method improved upon the vanilla model. Consequently, we found that our efforts of syntax-aware approach have been reflected by the model."
    },
    {
        "abstract": "The electromagnetic (EM) properties of two-component mixtures involving many disordered regularly and irregularly shaped crystals are studied. The effective relative permittivities are calculated utilizing the time-domain finite integration technique. The effective permittivity of disordered mixtures deviates from established mixing theories especially in cases of high permittivity contrast between inclusions and matrix material, and is strongly correlated to the cross-sectional area of the inclusion crystals. Electric energy density localizes at the edges and corners of inclusions in a manner independent of inclusion shape and influenced by EM propagation direction and surrounding inclusions. For mixtures with both disordered irregular and more organized cube inclusions, energy localization increases as the EM signal travels through the mixture before decreasing due to attenuation of the propagating EM signal. With a large number of inclusion crystals (here in the hundreds), it is found that the impact on effective permittivity from differences in individual inclusion shapes is negligible."
    },
    {
        "abstract": "To fulfil the tight area and memory constraints in IoT applications, the design of efficient Convolutional Neural Network (CNN) hardware becomes crucial. Quantization of CNN is one of the promising approach that allows the compression of large CNN into a much smaller one, which is very suitable for IoT applications. Among various proposed quantization schemes, Power-of-two (PoT) quantization enables efficient hardware implementation and small memory consumption for CNN accelerators, but requires retraining of CNN to retain its accuracy. This paper proposes a two-level post-training static quantization technique (DoubleQ) that combines the 8-bit and PoT weight quantization. The CNN weight is first quantized to 8-bit (level one), then further quantized to PoT (level two). This allows multiplication to be carried out using shifters, by expressing the weights in their PoT exponent form. DoubleQ also reduces the memory storage requirement for CNN, as only the exponent of the weights is needed for storage. However, DoubleQ trades the accuracy of the network for reduced memory storage. To recover the accuracy, a selection process (DoubleQExt) was proposed to strategically select some of the less informative layers in the network to be quantized with PoT at the second level. On ResNet-20, the proposed DoubleQ can reduce the memory consumption by 37.50% with 7.28% accuracy degradation compared to 8-bit quantization. By applying DoubleQExt, the accuracy is only degraded by 1.19% compared to 8-bit version while achieving a memory reduction of 23.05%. This result is also 1% more accurate than the state-of-the-art work (SegLog). The proposed DoubleQExt also allows flexible configuration to trade off the memory consumption with better accuracy, which is not found in the other state-of-the-art works. With the proposed two-level weight quantization, one can achieve a more efficient hardware architecture for CNN with minimal impact to the accuracy, which is crucial for IoT applicati..."
    },
    {
        "abstract": "Enterprises exist in a competitive manufacturing environment. To reduce production costs and effectively use production capacity to improve competitiveness, a hybrid production system is necessary. The flexible job shop (FJS) is a hybrid production system, and the FJS problem (FJSP) has drawn considerable attention in the past few decades. This paper examined the FJSP and, like previous studies, aimed to minimize the total order completion time (makespan). We developed a novel method that involves encoding feasible solutions in the genes of the initial chromosomes of a genetic algorithm (GA) and embedding the Taguchi method behind mating to increase the effectiveness of the GA. Two numerical experiments were conducted for evaluating the performance of the proposed algorithm relative to that of the Brandimarte MK1–MK10 benchmarks. The first experiment involved comparing the proposed algorithm and the traditional GA. The second experiment entailed comparing the proposed algorithm with those presented in previous studies. The results demonstrate that the proposed algorithm is superior to those reported in previous studies (except for that of Zhang et al.: the results in experiment MK7 were superior to those of Zhang, the results in experiments MK6 and MK10 were slightly inferior to those of Zhang, and the results were equivalent in other experiments) and effectively overcomes the encoding problem that occurs when a GA is used to solve the FJSP."
    },
    {
        "abstract": "The adaptive Runge–Kutta (ARK) method on multi-general-purpose graphical processing units (GPUs) is used for solving large nonlinear systems of first-order ordinary differential equations (ODEs) with over∼10000variables describing a large genetic network in systems biology for the biological clock. To carry out the computation of the trajectory of the system, a hierarchical structure of the ODEs is exploited, and an ARK solver is implemented in compute unified device architecture/C++ (CUDA/C++) on GPUs. The result is a 75-fold speedup for calculations of 2436 independent modules within the genetic network describing clock function relative to a comparable CPU architecture. These 2436 modules span one-quarter of the entire genome of a model fungal system, Neurospora crassa. The power of a GPU can in principle be harnessed by using warp-level parallelism, instruction level parallelism or both of them. Since the ARK ODE solver is entirely sequential, we propose a new parallel processing algorithm using warp-level parallelism for solving∼10000ODEs that belong to a large genetic network describing clock genome-level dynamics. A video is attached illustrating the general idea of the method on GPUs that can be used to provide new insights into the biological clock through single cell measurements on the clock."
    },
    {
        "abstract": "Distributed optical fiber sensors have gained an increasingly prominent role in structural-health monitoring. These are composed of an optical fiber cable in which a light impulse is launched by an opto-electronic device. The scattered light is of interest in the spectral domain: the spontaneous Brillouin spectrum is centered on the Brillouin frequency, which is related to the local strain and temperature changes in the optical fiber. When coupled with an industrial Brillouin optical time-domain analyzer (B-OTDA), an optical fiber cable can provide distributed measurements of strain and/or temperature, with a spatial resolution over kilometers of 40 cm. This paper focuses on the functioning of a B-OTDA device, where we address the problem of the improvement of spatial resolution. We model a Brillouin spectrum measured within an integration base of 1 m as the superposition of the elementary spectra contained in the base. Then, the spectral distortion phenomenon can be mathematically explained: if the strain is not constant within the integration base, the Brillouin spectrum is composed of several elementary spectra that are centered on different local Brillouin frequencies. We propose a source separation methodology approach to decompose a measured Brillouin spectrum into its spectral components. The local Brillouin frequencies and amplitudes are related to a portion of the integration base where the strain is constant. A layout algorithm allows the estimation of a strain profile with new spatial resolution chosen by the user. Numerical tests enable the finding of the optimal parameters, which provides a reduction to 1 cm of the 40-cm spatial resolution of the B-OTDA device. These parameters are highlighted during a comparison with a reference strain profile acquired by a 5-cm-resolution Rayleigh scatter analyzer under controlled conditions. In comparison with the B-OTDA strain profile, our estimated strain profile has better accuracy, with centimeter spatial resolut..."
    },
    {
        "abstract": "Deep learning-based salient object detection (SOD) methods have made great progress in recent years. However, most deep learning-based methods suffer from coarse object boundaries and expensive computations, especially in detecting objects with complex shapes. This paper presents an accurate and efficient SOD method that is based on a novel double-branch network that includes a body branch and an edge branch. To obtain an accurate edge, an edge profile enhancement module (EPEM) is embedded in the edge branch. In addition, a fusion feedback module (FFM) is embedded to integrate features from the two branches. To address the problem of expensive computations, channel attention module (CAM) is included to restrain redundant feature channels. Thus, the speed of the inference step can be improved with little reduction in the boundary accuracy. Experimental results on 9 datasets demonstrate that the proposed method performs favorably against 8 state-of-the-art methods in terms of both accuracy and efficiency. Additionally, our method achieves excellent detection results for objects with complex shapes."
    },
    {
        "abstract": "This paper deals with the design and evaluation of novel dynamic random access memory (DRAM) cells that have an oxide-based resistive element added for non-volatile operation. Two existing DRAM cells (namely the 3T1D and B3T cells) are utilized as volatile cores; a RRAM circuitry (consisting of an access control transistor and an oxide resistive RAM) is added to the core to extend its operation for non-volatile operation; two NVDRAM cells are then proposed. Considerations, such as the threshold voltage for the refresh operation and output read circuitry, are also considered. The impacts of the non-volatile circuitry as well as the DRAM core selection are assessed by HSPICE simulation. Figures of merit as related to performance, process variability, power consumption, and circuit design (critical charge and area of cell layout) are established for both volatile and non-volatile DRAM cells as well as memory arrays."
    },
    {
        "abstract": "To satisfy the complex surface machining requirement for the high attitude adjustment capability of the in-situ machining mechanism, this paper carries out the topology synthesis of the mechanism with dual platforms and decoupled motions of position and rotation, which allows translational positioning and precise attitude adjustment afterward. Firstly, to achieve spatial localization followed by precise attitude adjustment, the concept of a dual-platform system is introduced. The two platforms are designed to perform distinct motion tasks, and the decoupling principle of the dual-platform system based on Finite Instantaneous Screw (FIS) theory is investigated. Secondly, the continuous motion of the in-situ machining task is described using the simplest mathematical expressions, and the finite motion of the mechanism is derived. Thirdly, a topology synthesis method for in-situ machining of parallel mechanisms based on the decoupling principle is proposed. This method integrates the feasible limb structures of positioning and rotation mechanisms and identifies all limbs that satisfy the conditions. Finally, considering the practical requirements of in-situ machining of large components, the assembly conditions for the positioning and rotation mechanisms are established, the principles of connection between the two platforms are discussed and a decoupled connection between the two platforms is achieved. This paper provides a detailed description of the topological synthesis process for a dual-platform in-situ machining mechanism with decoupling of position and rotation. The decoupling principle of the dual-platform is explored, and the topological synthesis procedure for decoupling is presented. A novel topological structure of a dual-platform in-situ machining mechanism is successfully obtained, laying a solid foundation for subsequent kinematic analysis and performance evaluation."
    },
    {
        "abstract": "Many operations, be they military, police, rescue, or other field operations, require localization services and online situation awareness to make them effective. Questions such as how many people are inside a building and their locations are essential. In this paper, an online localization and situation awareness system is presented, called Mobile Urban Situation Awareness System (MUSAS), for gathering and maintaining localization information, to form a common operational picture. The MUSAS provides multiple localization services, as well as visualization of other sensor data, in a common frame of reference. The information and common operational picture of the system is conveyed to all parties involved in the operation, the field team, and people in the command post. In this paper, a general system architecture for enabling localization based situation awareness is designed and the MUSAS system solution is presented. The developed subsystem components and forming of the common operational picture are summarized, and the future potential of the system for various scenarios is discussed. In the demonstration, the MUSAS is deployed to an unknown building, in an ad hoc fashion, to provide situation awareness in an urban indoor military operation."
    },
    {
        "abstract": "Mobile instantaneous messaging (MIM) services significantly facilitate personal and business communications, inevitably consume substantial network resources, and potentially affect the network stability. In this paper, we aim to understand the traffic nature of MIM in cellular networks. Specifically, in order to reach credible conclusions, our research takes account of practical measurement records of MIM services from China Mobile at two different levels. First, a data set of individual message level (IML) traffic is exploited and reveals power-law distributed message length and lognormal distributed interarrival time, the heavy-tailness of which completely diverts from the geometric model and the exponential model recommended by the 3rd generation partnership project (3GPP). Second, another data set considers the statistical pattern of aggregated traffic within one whole base station, and demonstrates the accuracy ofα-stable models for the aggregated traffic. Furthermore, it verifies that theα-stable models are suitable for characterizing the traffic in both the conventional fixed core networks and the cellular access networks. At last, with the aid of the generalized central limit theorem, we build up a theoretical relation between the distributions of IML traffic and aggregated traffic."
    },
    {
        "abstract": "In software development, stakeholders of the same project often collaborate asynchronously through shared artifacts. A traceability system links a project's artifacts and therefore provides support for collaboration among stakeholders. Different stakeholders are interested in different types of traceability links. The literature often states that traceability is useful but expensive to build and maintain. However, there is no study showing reduction in effort when traceability links among various software artifacts are provided and used during the maintenance phase. This paper presents a study evaluating the benefits of using traceability among requirements, design, code, code inspections, builds, defects, and tests artifacts in the maintenance phase. Before the study, a survey was conducted at a large industrial firm to determine the type of links that different stakeholders are interested in. Twenty-five stakeholders from this firm participated in a survey to define the type of traceability links that were of interest to them. With this result, a traceability link model is proposed that categorizes different types of traceability links based on stakeholders' roles. This link model was used in the study. Twenty-eight subjects from industry and academia participated in the empirical study that was conducted after the survey. A prototype link-tracing tool, TraceLink, was developed and used in the study to present traceability links to the experimental group, whereas the control group was not given any links to solve the tasks. Five maintenance tasks were used in the study. The results show a significant improvement in task accuracy (86.06%) when traceability links were given to the subjects. In conclusion, a traceability model based on an industrial survey provided traceability views that are based on stakeholders' roles. This empirical study provides evidence that traceability links are effective in solving maintenance tasks with higher accuracy."
    },
    {
        "abstract": "The lack of good and up-to-date lab experiments form a major impediment in the domain of engineering education. Often, the lab experiments are outdated. The Virtual Labs project addresses the issue of lack of good lab facilities, as well as trained teachers, by making remote experimentation possible. The pedagogy is student-centric. The Virtual Labs project has also developed a novel methodology for field trials, outreach, and quality control. Virtual Labs also provide tremendous cost advantage. The Virtual Labs project is a wonderful example of an open educational resource developed by a multiinstitution multidiscipline project team. Over 100000 students are currently using the online labs under the Virtual Labs project. Many of these labs are being accessed outside the regular lab hours."
    },
    {
        "abstract": "Seismic wave attenuation in viscoelastic subsurface environments is quantified by the quality factor Q. Accurate estimation of the S-wave Q factor is crucial for improving resolution, imaging quality, interpretation accuracy, and predicting reservoir fluids and permeability in multicomponent seismic data. Although widely used, the spectral matching method has significant limitations in stability and accuracy when applied to noisy field data, stemming primarily from challenges in noise attenuation and transmission loss compensation. To address these limitations, we propose the spectral envelope matching (SENVM) method, which, unlike traditional spectral matching, focuses on spectral envelope differences, significantly reducing spectral noise interference, thereby improving stability and accuracy in matching outcomes. Based on Ganley’s theory, we propose an improved spectral envelope matching (ISENVM) method that builds on SENVM and incorporates transmission loss effects during estimation, thereby contributing to more accurate Q estimates. This method first extracts a seismic wavelet, followed by the centroid frequency shift (CFS) method to estimate formation Q values and construct an initial attenuation model. Then, the optimal formation Q values are determined using ISENVM. Applied to both noise-free and noisy synthetic vertical seismic profiling (VSP) down-going P- and S-wave data, both SENVM and ISENVM demonstrate superior anti-noise capabilities, providing more stable and accurate Q value estimates for P- and S-waves in thin layers compared to CFS. The successful application of ISENVM to field zero-offset three-component VSP data validates its effectiveness, contributing to a continuous model for the P- and S-wave Q factors. Finally, empirical formulas derived from regression analyses of P- and S-wave Q factors and velocities facilitate the estimation of S-wave Q factors and velocities for the Tuofutai block in the absence of reliable S-wave data."
    },
    {
        "abstract": "A multipath component distance (MCD)-based automatic clustering identification algorithm is proposed to group multipath components (MPCs) obtained from radio channels. The developed algorithm iteratively and dynamically assigns the MPCs to the best cluster thanks to the MCD metric. Its performance and robustness are compared with the K-means MCD algorithm using cluster data simulated with four reference scenarios of the WINNER II channel model. The results indicate that K-means MCD is outperformed for all investigated scenarios in spite of its having a lower computational complexity and faster convergence. Moreover, a by-product of the algorithm is an optimal MCD threshold, that is, the characteristic of the cluster statistical properties for a given propagation scenario. This parameter provides a stronger physical link between the MPCs distribution and the propagation scenario. Therefore, it could be introduced in radio channel models with clusterlike features."
    },
    {
        "abstract": "Deliberate amplitude clipping is a simple and well-known technique to reduce the peak-to-average power ratio of orthogonal frequency division multiplexing (OFDM) systems. In this paper, we propose a clipping technique for peak power reduction in orbital angular momentum (OAM) multiplexing systems with uniform circular array (UCA) antennas. In the proposed technique, clipping is performed on digital baseband signals prior to OAM beamforming and pulse-shaping filtering, which helps to avoid out-of-band radiation and affecting the orthogonality of the OAM modes. In addition, an iterative distortion recovery algorithm is proposed in order to mitigate performance degradation in bit error rate (BER) due to the clipping. The algorithm is derived by unfolding the clipping noise cancellation (CNC) algorithm for OFDM systems into layers and by introducing layer-wise learnable parameters. Simulation results show that for a realistic OAM multiplexing system with 256QAM signaling, the unfolded CNC exhibits excellent BER performance even when the conventional CNC suffers from a high error-floor. The combination of the proposed clipping and distortion recovery schemes provides a significant reduction in the peak power of the OAM signals at the cost of only a slight degradation in BER performance."
    },
    {
        "abstract": "Our world is rapidly changing, and swiftly evolving towards so-called “smart worlds”. The smart worlds starting with smart things such as the smart objects, smart city, smart manufacturing, and smart systems, will eventually encompass all aspects of the cyber, physical, social and mental world. A cyber-enabled completely new digital space featured with ubiquitous interconnections, integrations and interactions of physical, social, mental and other spaces will continuously bring out more and more changes. Cyberspace is actually the combinational outcome of various technologies including computers, communications, materials, intelligence and studies in perception, cognition, biology, sociology, etc., as well as advanced computing like the Internet/Web, pervasive networks, ubiquitous sensing and computing, the internet of things, the cloud, big data and so forth. These smart worlds are set to be the next important stage in human history. We have to be aware of the essential problems and crucial issues affecting in building truly smart worlds that benefit humanity, and simultaneously safeguard the natural environment for sustainable development and evolution. Therefore, this is the time to foresee future trends and identify what the grand challenges for smart worlds are. This Special Section in IEEE ACCESS has ten papers, and a brief summary about each paper is presented as follows."
    },
    {
        "abstract": "One of the main features of adaptive systems is an oscillatory convergence that exacerbates with the speed of adaptation. Recently, it has been shown that closed-loop reference models (CRMs) can result in improved transient performance over their open-loop counterparts in model reference adaptive control. In this paper, we quantify both the transient performance in the classical adaptive systems and their improvement with CRMs. In addition to deriving bounds on L-2 norms of the derivatives of the adaptive parameters that are shown to be smaller, an optimal design of CRMs is proposed that minimizes an underlying peaking phenomenon. The analytical tools proposed are shown to be applicable for a range of adaptive control problems including direct control and composite control with observer feedback. The presence of CRMs in adaptive backstepping and adaptive robot control is also discussed. Simulation results are presented throughout this paper to support the theoretical derivations."
    },
    {
        "abstract": "In recent decades, agricultural goods demand has grown exponentially due to the growth of the human population. Agricultural production demands new and simple techniques. Moreover, safe, efficient, and cost-effective methods are required for monitoring agriculture crops. This research aims to provide a simple image processing technique that detects and distinguishes the object (agricultural goods) in drone-based agrarian imagery. We used cotton crop images as experimental data in this research due to its different spectral characteristics according to drone camera sensors, minimum weather constraints, and flight schedule timing-related constraints. The proposed method used fuzzy reasoning-based tactics combined with RGB and HSV color spaces by manipulating image color pixel values and setting the upper/lower limits values of the colors for detection and distinguishing the agricultural objects such as white cotton bolls from the rest of the image."
    },
    {
        "abstract": "Nowadays, running applications on devices is restricted by limited computational capability and battery capacity, which needs the aid of mobile edge computing (MEC). This article aims to enhance MEC systems by employing revolutionary techniques: 1) adjusting wireless environment using reconfigurable intelligent surface (RIS), 2) exploiting opportunistically licensed spectrum using cognitive radio (CR), and 3) scavenging renewable energy using energy harvesting. We consider a RIS-assisted CR-MEC network where a secondary user (SU) powered by solar energy attempts to optimize computation. We study the computation rate maximization of SU, where it opportunistically either performs local computation or offloads data to the MEC server on a primary channel. A Markov decision process problem is formulated and then is firstly solved by a proposed deep policy gradient scheme, in which the system directly learns the policy from gradients of actions. To obtain higher stability, we subsequently propose a deep Q-learning scheme to derive a proper solution by maximizing the state-action value function. By taking the advantages of both policy-based and value-based methods, we further develop a deep actor-critic scheme, where an actor selects actions and a critic evaluates actions to acquire an optimal policy."
    },
    {
        "abstract": "Multi-objective robot exploration constitutes one of the most challenging tasks for autonomous robots performing in various operations and different environments. However, the optimal exploration path depends heavily on the objectives and constraints that both these operations and environments introduce. Typical environment constraints include partially known or completely unknown workspaces, limited-bandwidth communications, and sparse or dense clattered spaces. In such environments, the exploration robots must satisfy additional operational constraints, including time-critical goals, kinematic modeling, and resource limitations. Finding the optimal exploration path under these multiple constraints and objectives constitutes a challenging non-convex optimization problem. In our approach, we model the environment constraints in cost functions and utilize the cognitive-based adaptive optimization algorithm to meet time-critical objectives. The exploration path produced is optimal in the sense of globally minimizing the required time as well as maximizing the explored area of a partially unknown workspace. Since obstacles are sensed during operation, initial paths are possible to be blocked leading to a robot entrapment. A supervisor is triggered to signal a blocked passage and subsequently escape from the basin of cost function local minimum. Extensive simulations and comparisons in typical scenarios are presented to show the efficiency of the proposed approach."
    },
    {
        "abstract": "With the maturity of technologies, such as HTML5 and JavaScript, and with the increasing popularity of cross-platform frameworks, such as Apache Cordova, mobile cloud computing as a new design paradigm of mobile application developments is becoming increasingly more accessible to developers. Following this trend, future on-device mobile application ecosystems will not only comprise a mixture of native and remote applications, but also include multiple hybrid mobile cloud applications. The resource competition in such ecosystems and its impact over the performance of mobile cloud applications has not yet been studied. In this paper, we study this competition from a game theoretical perspective and examine how it affects the behavior of mobile cloud applications. Three offload decision models of cooperative and non-cooperative nature are constructed and their efficiency compared. We present an extension to the classic load balancing game to model the offload behaviors within a non-cooperative environment. Mixed-strategy Nash equilibria are derived for the non-cooperative offload game with complete information, which further quantifies the price of anarchy in such ecosystems. We present simulation results that demonstrate the differences between each decision model's efficiency. Our modeling approach facilitates further research in the design of the offload decision engines of mobile cloud applications. Our extension to the classic load balancing game broadens its applicability to real-life applications."
    },
    {
        "abstract": "The pervasive nature of big data technologies as witnessed in industry services and everyday life has given rise to an emergent, data-focused economy stemming from many aspects of industrial applications. The richness and vastness of these services are creating unprecedented research opportunities in a number of industrial fields including public health, urban studies, economics, finance, social science, and geography. We are moving towards the era of Big Data Services, which are deployed in a multi-scale complex distributed architecture. These services can be formed a high-level computational intelligence based on emerging analytical techniques such as big data analytics and web analytics. In this context, computational intelligence employs software tools from advanced analytics disciplines such as data mining, predictive analytics, and machine learning. At the same time, it becomes increasingly important to anticipate technical and practical challenges and to identify best practices learned through experience. This special session has included nine papers, and a brief summary about each paper is presented as follows."
    },
    {
        "abstract": "Industrial wireless channels feature rich multipath components and strong noise. Massively deployed nodes in an industrial network are often cheap devices. Under such circumstances, the received packets are prone to errors. The conventional method for guaranteeing data quality relies on the MAC layer approach, such as retransmissions. However, this approach creates a data misalignment problem that degrades the performance of multidevice cooperation. Therefore, we propose a robust quadrature ergodic chaotic parameter modulation (QECPM)-based receiver to avoid retransmission. The proposed method does not require timing synchronization. This method eliminates the possibility of cycle slipping, which has a major effect on performance. The bit error rate (BER) performance of the proposed receiver in the Nakagami-m channel is derived and verified by simulation. Using the proposed receiver, the multipath effect can be mitigated using a single scalar. We use software-defined radios (SDRs) to show that the proposed method is robust against timing synchronization errors in practice. Furthermore, we show that as long as there are retransmissions, misaligned packets are to be expected; however, when using the proposed receiver, the error bits are sparse enough to utilize the non-retransmission mode to maintain stable link rates. Our results show that the proposed receiver is robust to multipath, timing synchronization errors and data misalignment."
    },
    {
        "abstract": "The smart grid is an important hub of interdisciplinary research where researchers from different areas of science and technology combine their efforts to enhance the traditional electrical power grid. Due to these efforts, the traditional electrical grid is now evolving. The envisioned smart grid will bring social, environmental, ethical, legal and economic benefits. Smart grid systems increasingly involve machine-to-machine communication as well as human-to-human, or simple information retrieval. Thus, the dimensionality of the system is massive. The smart grid is the combination of different technologies, including control system theory, communication networks, pervasive computing, embedded sensing devices, electric vehicles, smart cities, renewable energy sources, Internet of Things, wireless sensor networks, cyber physical systems, and green communication. Due to these diverse activities and significant attention from researchers, education activities in the smart grid area are also growing."
    },
    {
        "abstract": "For most real-world systems, the exact description of possible faults is unknown, making these faults difficult to detect, and even more difficult to identify. The most promising way is to use multiple hypotheses for faults to find the best fitting fault model by comparing system measurements with the predictions of the multi-model algorithm. However, this may lead to the need for infinite hypotheses. We propose a novel multi-model approach that considers a small number of different models with a known macro-structure and unknown parameters, combining system identification with simultaneous fault diagnosis. The unknown parameters in the models are estimated using a maximum likelihood approach. The fitted models are then used in an interacting multiple model algorithm to determine the most likely model that best describes the system behavior at any moment in time. An overfitting problem emerging from short data sequences is discussed, and two solutions are introduced. First, a regularization term in the probability estimation is suggested to penalize frequent parameter changes that signal possible overfitting. Second, an algorithm with a shifted data set is presented. The effectiveness of the algorithms is demonstrated on a motion tracking problem where the different fault hypotheses represent the macro-behavior of a moving object, and the real system switches between different modes. In a comparison, the proposed algorithms are the only ones that reliably identify the defined faults. They can be easily adapted to other fault diagnosis problems."
    },
    {
        "abstract": "Today research activity is strongly driven by non-invasive exploration of living bodies. Wide-band reflectometry using adequate antennas system represents a possible way, but sometimes more accuracy is required which can be achieved by the use of implantable sensors that can closely investigate the interested tissues and are able to communicate with the external systems. For some applications, this communication can be unidirectional for monitoring purposes, but even in these cases, the transceiver should be carefully designed to obtain the necessary data while generating as low as possible radiofrequency power within the tissues. Blood and/or soft/hard tissue analysis can be based on this technique. The received signal is processed locally or sent to a remote medical center for further processing. The algorithms to extract the information are quite complex, and the low signal to noise ratio makes the analysis even more challenging. A bi-directional communication on the other hand represents a considerable advancement, when the sensor nodes are remotely controlled based on the feedback of the received data, for controlled drug release applications, as an example. Nevertheless, the reduced transmitter-receiver distance and presence of different high-loss tissues introduce strong reflections."
    },
    {
        "abstract": "Exploiting the parallelism in multiprocessor systems is a major challenge in modern computer science. Multicore programming demands a change in the way we design and use fundamental data structures. The standard collection of data structures and algorithms in C++11 is the sequential standard template library (STL). In this paper, we present their vision for the theory and practice for the design and implementation of a collection of highly concurrent fundamental data structures for multiprocessor application development with associated programming interface and advanced optimization support. Specifically, the proposed approach will provide a familiar, easy-to-use, and composable interface, similar to that of C++ STL. Each container type will be enhanced with internal support for nonblocking synchronization of its data access, thereby providing better safety and performance than traditional blocking synchronization by: 1) eliminating hazards such as deadlock, livelock, and priority inversion and 2) by being highly scalable in supporting large numbers of threads. The new library, lockless containers/data concurrency, will provide algorithms for handling fundamental computations in multithreaded contexts, and will incorporate these into libraries with familiar look and feel. The proposed approach will provide an immense boost in performance and software reuse, consequently productivity, for developers of scientific and systems applications, which are predominantly in C/C++. STL is widely used and a concurrent replacement library will have an immediate practical relevance and a significant impact on a variety of parallel programming domains including simulation, massive data mining, computational biology, financial engineering, and embedded control systems. As a proof-of-concept, this paper discusses the first design and implementation of a wait-free hash table."
    },
       {
        "abstract": "With today’s computer networks becoming increasingly dynamic, heterogeneous, and complex, there is great interest in deploying artificial intelligence (AI) based techniques for optimization and management of computer networks. AI techniques—that subsume multidisciplinary techniques from machine learning, optimization theory, game theory, control theory, and meta-heuristics—have long been applied to optimize computer networks in many diverse settings. Such an approach is gaining increased traction with the emergence of novel networking paradigms that promise to simplify network management (e.g., cloud computing, network functions virtualization, and software-defined networking) and provide intelligent services (e.g., future 5G mobile networks). Looking ahead, greater integration of AI into networking architectures can help develop a future vision of cognitive networks that will show network-wide intelligent behavior to solve problems of network heterogeneity, performance, and quality of service (QoS)."
    }
]